<?xml version="1.0"?>
<MethodSetup Method="DL::DNN_CPU">
  <GeneralInfo>
    <Info name="TMVA Release" value="4.2.1 [262657]"/>
    <Info name="ROOT Release" value="6.18/04 [397828]"/>
    <Info name="Creator" value="hchou"/>
    <Info name="Date" value="Sun Feb 16 14:13:10 2020"/>
    <Info name="Host" value="Linux lcgapp-centos7-x86-64-25.cern.ch 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux"/>
    <Info name="Dir" value="/afs/cern.ch/user/h/hchou/AMSProject/apflux"/>
    <Info name="Training events" value="215000"/>
    <Info name="TrainingTime" value="3.96047051e+01"/>
    <Info name="AnalysisType" value="Classification"/>
  </GeneralInfo>
  <Options>
    <Option name="V" modified="Yes">True</Option>
    <Option name="VerbosityLevel" modified="No">Verbose</Option>
    <Option name="VarTransform" modified="Yes">N</Option>
    <Option name="H" modified="Yes">False</Option>
    <Option name="CreateMVAPdfs" modified="No">False</Option>
    <Option name="IgnoreNegWeightsInTraining" modified="No">False</Option>
    <Option name="InputLayout" modified="No">0|0|0</Option>
    <Option name="BatchLayout" modified="No">0|0|0</Option>
    <Option name="Layout" modified="Yes">TANH|16,TANH|16,TANH|16,LINEAR</Option>
    <Option name="ErrorStrategy" modified="Yes">CROSSENTROPY</Option>
    <Option name="WeightInitialization" modified="Yes">XAVIERUNIFORM</Option>
    <Option name="RandomSeed" modified="No">0</Option>
    <Option name="ValidationSize" modified="No">20%</Option>
    <Option name="Architecture" modified="Yes">CPU</Option>
    <Option name="TrainingStrategy" modified="Yes">LearningRate=1e-2,Momentum=0.9,Repetitions=1,ConvergenceSteps=30,BatchSize=256,TestRepetitions=10,WeightDecay=1e-4,Regularization=None,DropConfig=0.0+0.5+0.5+0.5,</Option>
  </Options>
  <Variables NVar="6">
    <Variable VarIndex="0" Expression="lxl1" Label="lxl1" Title="lxl1" Unit="units" Internal="lxl1" Type="F" Min="-1.07785921e+01" Max="3.01704907e+00"/>
    <Variable VarIndex="1" Expression="lyl1" Label="lyl1" Title="lyl1" Unit="units" Internal="lyl1" Type="F" Min="-6.60879183e+00" Max="3.06884909e+00"/>
    <Variable VarIndex="2" Expression="lxl9" Label="lxl9" Title="lxl9" Unit="units" Internal="lxl9" Type="F" Min="-1.48751574e+01" Max="3.00993085e+00"/>
    <Variable VarIndex="3" Expression="lyl9" Label="lyl9" Title="lyl9" Unit="units" Internal="lyl9" Type="F" Min="-6.85651493e+00" Max="2.54658866e+00"/>
    <Variable VarIndex="4" Expression="lxfs" Label="lxfs" Title="lxfs" Unit="units" Internal="lxfs" Type="F" Min="-6.92413521e+00" Max="3.01469541e+00"/>
    <Variable VarIndex="5" Expression="lyfs" Label="lyfs" Title="lyfs" Unit="units" Internal="lyfs" Type="F" Min="-5.21348000e+00" Max="2.60541844e+00"/>
  </Variables>
  <Spectators NSpec="0"/>
  <Classes NClass="2">
    <Class Name="Signal" Index="0"/>
    <Class Name="Background" Index="1"/>
  </Classes>
  <Transformations NTransformations="1">
    <Transform Name="Normalize">
      <Selection>
        <Input NInputs="6">
          <Input Type="Variable" Label="lxl1" Expression="lxl1"/>
          <Input Type="Variable" Label="lyl1" Expression="lyl1"/>
          <Input Type="Variable" Label="lxl9" Expression="lxl9"/>
          <Input Type="Variable" Label="lyl9" Expression="lyl9"/>
          <Input Type="Variable" Label="lxfs" Expression="lxfs"/>
          <Input Type="Variable" Label="lyfs" Expression="lyfs"/>
        </Input>
        <Output NOutputs="6">
          <Output Type="Variable" Label="lxl1" Expression="lxl1"/>
          <Output Type="Variable" Label="lyl1" Expression="lyl1"/>
          <Output Type="Variable" Label="lxl9" Expression="lxl9"/>
          <Output Type="Variable" Label="lyl9" Expression="lyl9"/>
          <Output Type="Variable" Label="lxfs" Expression="lxfs"/>
          <Output Type="Variable" Label="lyfs" Expression="lyfs"/>
        </Output>
      </Selection>
      <Class ClassIndex="0">
        <Ranges>
          <Range Index="0" Min="-1.0778592109680176e+01" Max="3.0170490741729736e+00"/>
          <Range Index="1" Min="-5.6716537475585938e+00" Max="2.9918751716613770e+00"/>
          <Range Index="2" Min="-1.4875157356262207e+01" Max="3.0099308490753174e+00"/>
          <Range Index="3" Min="-6.8565149307250977e+00" Max="2.5465886592864990e+00"/>
          <Range Index="4" Min="-6.9241352081298828e+00" Max="3.0146954059600830e+00"/>
          <Range Index="5" Min="-5.2134799957275391e+00" Max="2.6007392406463623e+00"/>
        </Ranges>
      </Class>
      <Class ClassIndex="1">
        <Ranges>
          <Range Index="0" Min="-1.0268076896667480e+01" Max="2.7867364883422852e+00"/>
          <Range Index="1" Min="-6.6087918281555176e+00" Max="3.0688490867614746e+00"/>
          <Range Index="2" Min="-7.1402177810668945e+00" Max="2.7484481334686279e+00"/>
          <Range Index="3" Min="-5.2347531318664551e+00" Max="2.4964630603790283e+00"/>
          <Range Index="4" Min="-5.5111508369445801e+00" Max="2.8158082962036133e+00"/>
          <Range Index="5" Min="-1.8996458053588867e+00" Max="2.6054184436798096e+00"/>
        </Ranges>
      </Class>
      <Class ClassIndex="2">
        <Ranges>
          <Range Index="0" Min="-1.0778592109680176e+01" Max="3.0170490741729736e+00"/>
          <Range Index="1" Min="-6.6087918281555176e+00" Max="3.0688490867614746e+00"/>
          <Range Index="2" Min="-1.4875157356262207e+01" Max="3.0099308490753174e+00"/>
          <Range Index="3" Min="-6.8565149307250977e+00" Max="2.5465886592864990e+00"/>
          <Range Index="4" Min="-6.9241352081298828e+00" Max="3.0146954059600830e+00"/>
          <Range Index="5" Min="-5.2134799957275391e+00" Max="2.6054184436798096e+00"/>
        </Ranges>
      </Class>
    </Transform>
  </Transformations>
  <MVAPdfs/>
  <Weights NetDepth="4" InputDepth="1" InputHeight="1" InputWidth="6" BatchSize="1" BatchDepth="1" BatchHeight="256" BatchWidth="6" LossFunction="C" Initialization="F" Regularization="0" OutputFunction="S" WeightDecay="9.9999997473787516e-05">
    <DenseLayer Width="16" ActivationFunction="3">
      <Weights Rows="16" Columns="6">
        -8.219724e-01  1.928011e-01  -1.028015e+00  4.128271e-01  3.521804e-01  3.364773e+00  -6.187280e-01  1.433505e+00  -7.368795e-01  1.279536e+00  -6.203571e-02  2.336153e+00  6.072993e-01  1.033161e+00  8.056816e-01  1.511802e+00  7.929215e-01  3.297579e+00  -4.988217e-01  1.480783e+00  -4.279085e-01  7.825510e-01  -4.431948e-01  1.835643e+00  7.226473e-01  1.712644e+00  1.695490e-01  6.711009e-01  -9.671409e-01  -3.568834e+00  -6.974345e-01  1.001012e+00  -2.650360e-01  9.629968e-01  8.835429e-03  2.050230e+00  3.925502e-01  9.477860e-01  4.493468e-01  -6.476313e-03  -4.168745e-01  -2.983830e+00  -7.345791e-01  -1.579157e+00  -7.171898e-01  -9.201026e-01  1.628580e+00  3.558795e+00  -3.513780e-02  -2.770630e-01  -6.163578e-01  -1.703131e-01  -3.881578e-02  2.230865e+00  -6.721442e-01  -6.753084e-01  4.497828e-02  -5.772634e-01  3.675022e-01  3.066701e+00  9.077637e-01  1.331042e+00  5.619249e-01  2.585290e-02  -1.055774e+00  -3.201148e+00  -1.042886e+00  -1.814166e+00  -1.865824e-01  -5.857146e-01  1.374564e+00  3.805277e+00  9.486468e-01  7.840631e-01  1.137359e+00  1.458473e+00  9.538176e-01  2.891764e+00  5.964156e-01  1.519271e+00  8.877816e-01  5.471144e-01  -1.345028e+00  -4.078295e+00  1.041366e+00  1.310797e+00  7.710685e-01  6.476051e-01  -1.502027e+00  -4.466719e+00  -9.327307e-01  -1.714483e+00  -6.558187e-01  -2.576443e-01  1.559462e+00  3.270799e+00  
      </Weights>
      <Biases Rows="16" Columns="1">
        -5.790716e-01  -9.474336e-01  9.420386e-01  -6.924228e-01  6.040213e-01  -4.819553e-01  1.063727e+00  -4.666521e-01  -7.157514e-01  -1.170450e+00  5.533242e-01  -8.363000e-01  1.013156e+00  1.206984e+00  1.547179e+00  -4.768941e-01  
      </Biases>
    </DenseLayer>
    <DenseLayer Width="16" ActivationFunction="3">
      <Weights Rows="16" Columns="16">
        -9.918060e-02  -1.209917e-01  -2.065906e-03  -6.601038e-02  3.884141e+00  -5.434380e-03  2.120029e+00  -2.765356e+00  -7.608430e-01  -1.188872e+00  1.036117e+00  -5.960312e+00  4.153041e-02  2.155816e+00  9.687206e-01  -1.810097e+00  -3.738583e-02  -1.260698e-01  -5.291748e-02  -1.105601e-01  5.520072e-01  -1.109610e-01  2.027141e+00  -7.371054e-01  -1.104445e+00  -4.133705e+00  3.931708e-01  -1.091501e+00  -7.362766e-02  2.347749e+00  3.874011e+00  -3.349811e-02  6.706946e-02  1.034035e-01  5.207586e-02  5.944975e-03  -9.781594e-01  5.657297e-02  -2.369205e+00  1.001428e+00  8.342903e-01  3.151097e+00  -4.226696e-01  1.806093e+00  6.613044e-02  -4.992053e+00  -4.339347e+00  9.088880e-01  2.445739e-01  1.233076e-01  3.366463e-02  1.195361e-01  -3.707786e+00  2.503008e-02  -5.949216e-01  3.329603e+00  4.680901e-01  6.116101e-01  -3.365640e+00  1.154750e+00  5.208442e-02  -3.337894e-01  -3.238568e-01  5.188698e+00  -1.186297e-01  -1.604042e-01  3.178453e-03  -1.252551e-01  3.164806e+00  3.941309e-02  2.445860e+00  -2.065054e+00  -8.926182e-01  -1.664470e+00  9.048212e-01  -5.159165e+00  -3.454218e-02  2.781261e+00  1.293048e+00  -1.465660e+00  -1.772170e-01  -6.731193e-02  -3.408210e-02  -6.299739e-02  3.755225e+00  -4.323916e-04  5.999524e-01  -3.232961e+00  -6.121011e-01  -4.237625e-01  2.679338e+00  -1.404927e+00  -3.099038e-03  6.280638e-01  3.715191e-01  -4.593901e+00  1.630088e-01  7.059809e-02  -9.438961e-02  5.645353e-02  -6.610078e+00  8.120850e-03  -1.302675e+00  4.260963e+00  5.640231e-01  9.026834e-01  -1.324663e+00  3.992879e+00  -6.837431e-03  -1.021432e+00  -5.148010e-01  3.054588e+00  6.868058e-02  1.304559e-01  -8.629226e-03  9.028525e-02  -2.339114e+00  -5.161051e-02  -2.437222e+00  1.826414e+00  9.503587e-01  1.816884e+00  -8.529847e-01  5.314406e+00  2.042506e-02  -3.691498e+00  -1.723110e+00  1.380950e+00  -3.856199e-02  -1.939986e-02  -9.353051e-02  1.045120e-01  -3.740338e-01  -1.355276e-03  -1.844548e+00  6.764031e-01  1.458727e+00  2.490487e+00  7.389901e-02  1.048123e-01  -1.171259e-01  -1.639418e+00  -2.938304e+00  4.680272e-01  -8.837557e-02  -4.680141e-02  1.470900e-02  -3.762272e-02  1.280670e+00  2.208910e-02  2.643319e+00  -1.278206e+00  -8.260246e-01  -2.669778e+00  5.815214e-01  -2.893490e+00  -4.846714e-02  6.092979e+00  3.321116e+00  -1.162841e+00  -2.212630e-02  -7.543802e-03  8.671050e-02  -1.793158e-01  6.617827e-01  2.076566e-02  1.870709e+00  -3.743143e-01  -1.308460e+00  -2.820688e+00  2.530647e-01  -1.040966e+00  1.250924e-01  1.622476e+00  2.990616e+00  -3.072462e-01  -6.512948e-02  1.062399e-02  3.975648e-02  -1.591118e-01  2.657176e-01  7.975752e-03  1.817749e+00  -4.286538e-01  -1.166749e+00  -3.541344e+00  3.218604e-01  -8.183411e-01  7.777631e-02  1.666998e+00  2.879787e+00  -2.836126e-01  2.993009e-01  2.230025e-01  1.340254e-01  1.832867e-01  -2.450478e+00  1.452325e-01  -4.498149e-01  2.804569e+00  3.082649e-01  2.969223e-01  -3.429225e+00  1.311093e+00  7.695533e-02  -9.008500e-01  -1.533946e-01  4.309887e+00  2.592026e-01  1.531747e-01  8.242211e-02  1.170581e-01  -3.246215e+00  1.247147e-01  -8.539222e-01  2.729869e+00  2.762554e-01  1.022984e-01  -2.960071e+00  1.233304e+00  6.091724e-02  -2.093395e-01  -2.966661e-01  3.917119e+00  -6.582960e-02  -1.309838e-01  -5.865269e-02  -1.311665e-01  7.695180e-01  -9.211057e-02  1.823604e+00  -4.422852e-01  -1.060362e+00  -4.029574e+00  1.708351e-01  -1.033990e+00  -6.177437e-02  2.209203e+00  4.147512e+00  -6.273472e-01  -7.679973e-02  6.396173e-03  2.991017e-02  -1.245841e-02  5.883055e+00  3.736774e-02  1.014947e+00  -4.964938e+00  -6.608852e-01  -6.425493e-01  1.743226e+00  -2.488021e+00  5.708290e-03  7.812170e-01  4.917119e-01  -4.277739e+00  
      </Weights>
      <Biases Rows="16" Columns="1">
        2.719890e-02  1.370910e+00  -1.118248e+00  1.424384e+00  2.764286e-01  -9.905059e-01  4.284350e-01  -3.188063e-01  -1.093615e+00  8.673527e-01  2.065546e+00  1.916832e+00  1.225172e+00  1.291661e+00  1.490847e+00  -5.778065e-01  
      </Biases>
    </DenseLayer>
    <DenseLayer Width="16" ActivationFunction="3">
      <Weights Rows="16" Columns="16">
        4.150230e-02  -8.555995e-01  2.498030e-01  -4.560927e-02  -8.078189e-02  -1.003887e-01  -1.320775e-02  1.346268e-01  1.238364e+00  -2.119460e-01  -2.042881e+00  -2.222810e+00  7.614551e-02  -6.489713e-02  -7.559185e-01  -1.178725e-01  3.213219e+00  1.860606e-02  -3.527859e-01  -3.436330e-01  1.749405e+00  2.897675e-01  -1.410877e+00  -9.146108e-01  -2.821628e-01  3.357333e-01  3.712704e-03  3.418106e-02  -1.126627e-01  -3.245080e-01  2.493990e-01  7.847299e-01  -1.666277e-01  -1.355211e+00  2.250254e+00  1.795303e-01  -4.780257e-01  -1.192728e-02  2.168448e-01  3.658860e-01  7.526654e-01  -1.262078e+00  -2.571103e-01  -5.939132e-01  1.284687e-01  1.228554e-01  -1.706288e+00  6.995018e-02  -4.414357e-01  -2.857033e-02  2.348694e-01  1.368725e+00  -3.159240e-01  -2.178772e+00  7.789135e-01  2.251960e-01  6.357912e-02  -2.191611e-01  6.063770e-03  -1.100746e-01  1.002891e+00  9.584680e-01  -1.315371e-01  -1.873095e+00  1.103532e+00  2.835612e-01  -6.179508e-02  -2.455608e-01  7.073597e-01  8.639282e-01  -3.377028e+00  -4.140659e-01  2.521748e-02  2.857260e-01  1.077909e-01  2.008733e-01  -3.907290e-01  -1.985518e-01  1.309614e-02  1.787678e+00  -8.696546e-01  -1.103702e-01  5.982750e-02  7.237574e-01  -5.257648e-01  -1.060801e+00  2.818374e+00  2.031753e-01  -9.421222e-02  -2.481223e-01  -9.176911e-02  -1.020531e-01  4.770840e-01  3.992518e-01  -9.846463e-02  -2.260468e+00  2.396286e-02  1.972499e+00  -1.124918e+00  -1.070274e-01  2.144976e-01  7.394097e-02  -3.911993e-02  -2.837735e-01  -1.145695e+00  5.189728e-01  5.626116e-01  7.325803e-01  1.376864e-02  -3.943328e-02  2.341333e+00  1.518206e-02  3.773604e-02  -9.909298e-01  3.670670e-01  -9.022166e-02  -2.803594e-01  -2.098640e-02  2.491482e-02  1.361041e-01  1.200440e+00  -3.216226e-01  -1.524792e+00  -2.021596e+00  8.605632e-02  -5.149641e-02  -9.985173e-01  1.530587e-02  -2.140666e-01  -1.086706e+00  2.480013e+00  8.435256e-02  -5.300967e-01  -2.298999e-01  1.091018e-01  5.556396e-01  4.541334e-01  -2.274433e+00  -8.521044e-02  -3.494468e-01  1.027426e-01  -2.738799e-02  -1.186167e+00  -8.265638e-02  -1.749772e-01  6.664287e-02  4.430963e-02  1.879729e+00  -5.257817e-02  -1.185139e+00  3.422539e-01  1.257323e-01  1.965533e-01  -1.933081e-01  -5.260306e-02  1.000919e-02  2.346770e+00  2.702768e+00  -1.393562e-01  -5.910826e-01  -1.154485e+00  -4.308457e-01  6.745613e-01  2.692830e-01  -1.997856e+00  4.081686e-02  3.680542e-01  2.149136e+00  1.876303e-01  -1.285771e+00  -1.899504e-01  -7.006609e-02  1.294118e-01  1.553502e-01  -4.115145e-01  -4.394300e-01  -2.193317e+00  -1.699478e-01  4.298480e-01  1.998466e-01  -2.823216e+00  -3.064637e-01  6.139087e-01  2.537836e+00  2.303071e-01  -7.560133e-01  -8.778577e-02  3.718556e-02  1.815022e-01  5.820929e-02  -2.155521e-01  -6.135375e-01  -2.237157e-01  -7.220377e-03  1.087840e-01  2.308802e+00  -2.931904e-02  -1.272651e+00  3.279061e-01  9.802805e-02  2.222783e-01  -9.367009e-02  6.290822e-02  5.863132e-02  1.794593e+00  2.136140e+00  -5.397333e-02  -5.593559e-01  -6.743382e-01  -7.696104e-01  1.285334e+00  8.683032e-02  -9.286842e-01  -8.710586e-02  3.200157e-01  1.301165e+00  2.589180e-01  -2.778943e+00  -2.161697e-01  -2.706234e-01  1.063479e-01  -4.899917e-02  -4.769933e-01  -1.545434e-01  4.410568e-01  1.329195e-01  -2.124005e-01  -8.273200e-01  5.790484e-01  1.600502e+00  -1.376560e+00  -1.670320e-01  -9.447421e-02  2.410458e-01  3.420136e-02  1.428363e-01  -4.978032e-01  -7.647440e-01  1.111060e-01  3.429020e+00  -2.530670e-01  -1.037059e-01  6.170277e-02  2.237322e+00  -2.814887e-03  -1.798964e+00  4.620099e-01  2.328641e-01  5.581790e-02  -1.261355e-02  1.015497e-01  4.802407e-03  1.561601e+00  1.556403e+00  2.616867e-02  -6.558502e-01  
      </Weights>
      <Biases Rows="16" Columns="1">
        -1.104684e+00  -8.186345e-02  -2.128244e-01  5.348298e-01  -2.174749e-01  2.471640e-01  3.149399e-01  -8.571618e-01  -1.181050e-01  1.196738e+00  8.956728e-02  5.217654e-02  1.036555e+00  -1.070369e-01  -3.621281e-01  9.333833e-01  
      </Biases>
    </DenseLayer>
    <DenseLayer Width="1" ActivationFunction="0">
      <Weights Rows="1" Columns="16">
        -1.301123e-01  1.299965e-01  -1.146329e-01  -1.574426e-01  1.572242e-01  -1.260364e-01  1.242712e-01  -1.233816e-01  -1.215257e-01  -1.334432e-01  -1.258835e-01  -1.445811e-01  -1.339315e-01  -1.566038e-01  1.505302e-01  -1.391974e-01  
      </Weights>
      <Biases Rows="1" Columns="1">
        2.388637e+00  
      </Biases>
    </DenseLayer>
  </Weights>
</MethodSetup>
